{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Catastro Data Processing\n",
        "\n",
        "This notebook processes three catastro JSON files:\n",
        "- `catastro_parcels.json` - Parcel information (unique referencia_catastral)\n",
        "- `catastro_buildings.json` - Building information\n",
        "- `catastro_units.json` - Unit information\n",
        "\n",
        "The goal is to create a comprehensive dataset with one row per parcel, including aggregated information from buildings and units.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Load and Examine Data Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON files...\n",
            "Loaded 10110 parcels\n",
            "Loaded 6495 buildings\n",
            "Loaded 7924 units\n"
          ]
        }
      ],
      "source": [
        "# Load JSON files\n",
        "print(\"Loading JSON files...\")\n",
        "\n",
        "with open('catastro_parcels.json', 'r', encoding='utf-8') as f:\n",
        "    parcels_data = json.load(f)\n",
        "    \n",
        "with open('catastro_buildings.json', 'r', encoding='utf-8') as f:\n",
        "    buildings_data = json.load(f)\n",
        "    \n",
        "with open('catastro_units.json', 'r', encoding='utf-8') as f:\n",
        "    units_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(parcels_data)} parcels\")\n",
        "print(f\"Loaded {len(buildings_data)} buildings\")\n",
        "print(f\"Loaded {len(units_data)} units\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PARCELS - Sample structure:\n",
            "Keys: ['id', 'referencia_catastral', 'municipio', 'codigo_municipio', 'provincia', 'codigo_provincia', 'superficie_parcela', 'uso_parcela', 'geometry', 'last_update']\n",
            "Sample record:\n",
            "  id: 2872\n",
            "  referencia_catastral: 000100100DD99E\n",
            "  municipio: SELVA\n",
            "  codigo_municipio: 07058\n",
            "  provincia: Illes Balears\n",
            "\n",
            "==================================================\n",
            "\n",
            "BUILDINGS - Sample structure:\n",
            "Keys: ['id', 'parcel_ref', 'building_type', 'description', 'built_area', 'staircase', 'floor', 'door', 'municipality', 'province', 'last_update']\n",
            "Sample record:\n",
            "  id: 1\n",
            "  parcel_ref: 000100200DD89A\n",
            "  building_type: VIVIENDA\n",
            "  description: VIVIENDA UNIFAMILIAR\n",
            "  built_area: 22\n",
            "\n",
            "==================================================\n",
            "\n",
            "UNITS - Sample structure:\n",
            "Keys: ['id', 'parcel_ref', 'unit_ref', 'car', 'cc1', 'cc2', 'province_code', 'municipality_code', 'cadastral_municipio', 'use_type', 'floor_area', 'year_built', 'participation', 'street_name', 'street_type', 'street_code', 'portal_number', 'portal_suffix', 'floor', 'door', 'staircase', 'postal_code', 'address_code', 'local_zoning_code', 'polygon_number', 'parcel_number', 'local_place_name', 'parcel_grouping_code', 'province', 'municipality', 'raw_address_text', 'num_entries', 'spr_code', 'spr_type_code', 'spr_type_desc', 'spr_url', 'spr_entity_name', 'last_update', 'geometry']\n",
            "Sample record:\n",
            "  id: 4\n",
            "  parcel_ref: 000100100DD99E\n",
            "  unit_ref: UR\n",
            "  car: None\n",
            "  cc1: None\n"
          ]
        }
      ],
      "source": [
        "# Examine structure of first few records\n",
        "print(\"PARCELS - Sample structure:\")\n",
        "if parcels_data:\n",
        "    print(\"Keys:\", list(parcels_data[0].keys()))\n",
        "    print(\"Sample record:\")\n",
        "    for key, value in list(parcels_data[0].items())[:5]:\n",
        "        print(f\"  {key}: {value}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"BUILDINGS - Sample structure:\")\n",
        "if buildings_data:\n",
        "    print(\"Keys:\", list(buildings_data[0].keys()))\n",
        "    print(\"Sample record:\")\n",
        "    for key, value in list(buildings_data[0].items())[:5]:\n",
        "        print(f\"  {key}: {value}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"UNITS - Sample structure:\")\n",
        "if units_data:\n",
        "    print(\"Keys:\", list(units_data[0].keys()))\n",
        "    print(\"Sample record:\")\n",
        "    for key, value in list(units_data[0].items())[:5]:\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Convert to DataFrames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parcels DataFrame shape: (10110, 10)\n",
            "Buildings DataFrame shape: (6495, 11)\n",
            "Units DataFrame shape: (7924, 39)\n",
            "\n",
            "Columns containing 'referencia' or 'catastral':\n",
            "Parcels: ['referencia_catastral']\n",
            "Buildings: []\n",
            "Units: []\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrames\n",
        "df_parcels = pd.DataFrame(parcels_data)\n",
        "df_buildings = pd.DataFrame(buildings_data)\n",
        "df_units = pd.DataFrame(units_data)\n",
        "\n",
        "print(f\"Parcels DataFrame shape: {df_parcels.shape}\")\n",
        "print(f\"Buildings DataFrame shape: {df_buildings.shape}\")\n",
        "print(f\"Units DataFrame shape: {df_units.shape}\")\n",
        "\n",
        "# Check for referencia_catastral columns\n",
        "print(\"\\nColumns containing 'referencia' or 'catastral':\")\n",
        "for df_name, df in [('Parcels', df_parcels), ('Buildings', df_buildings), ('Units', df_units)]:\n",
        "    ref_cols = [col for col in df.columns if 'referencia' in col.lower() or 'catastral' in col.lower()]\n",
        "    print(f\"{df_name}: {ref_cols}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using correct column mappings:\n",
            "Parcels ID column: referencia_catastral\n",
            "Buildings reference column: parcel_ref\n",
            "Units reference column: parcel_ref\n",
            "\n",
            "Column verification:\n",
            "'referencia_catastral' in parcels: True\n",
            "'parcel_ref' in buildings: True\n",
            "'parcel_ref' in units: True\n",
            "\n",
            "Key columns found:\n",
            "Parcels: ['referencia_catastral', 'municipio', 'codigo_municipio', 'provincia', 'codigo_provincia', 'superficie_parcela']\n",
            "Buildings: ['parcel_ref', 'building_type', 'built_area']\n",
            "Units: ['parcel_ref', 'use_type', 'floor_area', 'year_built']\n"
          ]
        }
      ],
      "source": [
        "# Define the correct column mappings based on the data structure\n",
        "parcel_ref_col = 'referencia_catastral'  # Unique identifier in parcels\n",
        "building_ref_col = 'parcel_ref'          # Reference to parcels in buildings\n",
        "unit_ref_col = 'parcel_ref'              # Reference to parcels in units\n",
        "\n",
        "print(f\"Using correct column mappings:\")\n",
        "print(f\"Parcels ID column: {parcel_ref_col}\")\n",
        "print(f\"Buildings reference column: {building_ref_col}\")\n",
        "print(f\"Units reference column: {unit_ref_col}\")\n",
        "\n",
        "# Verify the columns exist\n",
        "print(f\"\\nColumn verification:\")\n",
        "print(f\"'{parcel_ref_col}' in parcels: {parcel_ref_col in df_parcels.columns}\")\n",
        "print(f\"'{building_ref_col}' in buildings: {building_ref_col in df_buildings.columns}\")\n",
        "print(f\"'{unit_ref_col}' in units: {unit_ref_col in df_units.columns}\")\n",
        "\n",
        "# Show key columns available\n",
        "print(f\"\\nKey columns found:\")\n",
        "print(f\"Parcels: {[col for col in df_parcels.columns if any(term in col.lower() for term in ['referencia', 'superficie', 'municipio', 'provincia'])]}\")\n",
        "print(f\"Buildings: {[col for col in df_buildings.columns if any(term in col.lower() for term in ['parcel_ref', 'built_area', 'building_type'])]}\")\n",
        "print(f\"Units: {[col for col in df_units.columns if any(term in col.lower() for term in ['parcel_ref', 'floor_area', 'use_type', 'year_built'])]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parcels - Unique referencia_catastral: 10110, Total records: 10110\n",
            "Is unique: True\n",
            "\n",
            "Sample referencia_catastral values:\n",
            "['000100100DD99E', '000100100DE90A', '000100100DE90B', '000100200DE90A', '000100200DE90B', '000100300DD99G', '000100300DE90B', '000100400DD99G', '000100400DE90B', '000100500DD99G']\n"
          ]
        }
      ],
      "source": [
        "# Check uniqueness of referencia_catastral in parcels\n",
        "if parcel_ref_col:\n",
        "    unique_parcels = df_parcels[parcel_ref_col].nunique()\n",
        "    total_parcels = len(df_parcels)\n",
        "    print(f\"Parcels - Unique {parcel_ref_col}: {unique_parcels}, Total records: {total_parcels}\")\n",
        "    print(f\"Is unique: {unique_parcels == total_parcels}\")\n",
        "    \n",
        "    # Show sample values\n",
        "    print(f\"\\nSample {parcel_ref_col} values:\")\n",
        "    print(df_parcels[parcel_ref_col].head(10).tolist())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Aggregate Buildings and Units Data by Parcel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing buildings data...\n",
            "Building aggregations shape: (1982, 13)\n",
            "Building aggregations columns: ['parcel_ref', 'num_buildings', 'total_built_area', 'avg_built_area', 'max_built_area', 'buildings_areas', 'buildings_types', 'buildings_floors', 'buildings_descriptions', 'buildings_details_json', 'unique_building_types', 'building_type_diversity', 'primary_building_type']\n",
            "Sample building aggregation (showing structured building details):\n",
            "       parcel_ref  num_buildings     buildings_areas  \\\n",
            "0  000100100DD88G              4    179, 145, 38, 42   \n",
            "1  000100200DD88G              5  47, 92, 41, 27, 46   \n",
            "2  000100200DD89A              1                  22   \n",
            "\n",
            "                                     buildings_types  total_built_area  \n",
            "0         VIVIENDA, VIVIENDA, PORCHE 100%, DEPORTIVO               404  \n",
            "1  VIVIENDA, VIVIENDA, DEPORTIVO, ALMACEN, PORCHE...               253  \n",
            "2                                           VIVIENDA                22  \n"
          ]
        }
      ],
      "source": [
        "# Aggregate buildings data by parcel\n",
        "print(\"Processing buildings data...\")\n",
        "\n",
        "# Create building aggregations\n",
        "building_agg = df_buildings.groupby(building_ref_col).agg({\n",
        "    'id': 'count',  # Count of buildings per parcel\n",
        "    'built_area': ['sum', 'mean', 'max'],  # Built area statistics\n",
        "}).round(2)\n",
        "\n",
        "# Flatten column names\n",
        "building_agg.columns = ['num_buildings', 'total_built_area', 'avg_built_area', 'max_built_area']\n",
        "\n",
        "# Add individual building details - structured approach for unlimited buildings\n",
        "def process_buildings_for_parcel(group):\n",
        "    # Lists for CSV format\n",
        "    built_areas = []\n",
        "    building_types = []\n",
        "    floors = []\n",
        "    descriptions = []\n",
        "    \n",
        "    # Detailed dict for JSON format\n",
        "    building_details = []\n",
        "    \n",
        "    for idx, building in group.iterrows():\n",
        "        built_area = building['built_area'] if pd.notna(building['built_area']) else 0\n",
        "        building_type = building['building_type'] if pd.notna(building['building_type']) else 'Unknown'\n",
        "        floor = building['floor'] if pd.notna(building['floor']) else 'Unknown'\n",
        "        description = building['description'] if pd.notna(building['description']) else 'Unknown'\n",
        "        staircase = building['staircase'] if pd.notna(building['staircase']) else 'Unknown'\n",
        "        door = building['door'] if pd.notna(building['door']) else 'Unknown'\n",
        "        \n",
        "        # Add to lists (for CSV columns)\n",
        "        built_areas.append(built_area)\n",
        "        building_types.append(building_type)\n",
        "        floors.append(floor)\n",
        "        descriptions.append(description)\n",
        "        \n",
        "        # Add to detailed structure (for JSON column)\n",
        "        building_details.append({\n",
        "            'building_id': int(building['id']),\n",
        "            'built_area': built_area,\n",
        "            'building_type': building_type,\n",
        "            'description': description,\n",
        "            'floor': floor,\n",
        "            'staircase': staircase,\n",
        "            'door': door\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        'areas_csv': ', '.join(map(str, built_areas)),\n",
        "        'types_csv': ', '.join(building_types),\n",
        "        'floors_csv': ', '.join(floors),\n",
        "        'descriptions_csv': ', '.join(descriptions),\n",
        "        'buildings_details_json': json.dumps(building_details, ensure_ascii=False)\n",
        "    }\n",
        "\n",
        "# Process all buildings for each parcel\n",
        "buildings_processed = df_buildings.groupby(building_ref_col).apply(process_buildings_for_parcel)\n",
        "\n",
        "# Add the structured building data to aggregations\n",
        "building_agg['buildings_areas'] = buildings_processed.apply(lambda x: x['areas_csv'])\n",
        "building_agg['buildings_types'] = buildings_processed.apply(lambda x: x['types_csv'])\n",
        "building_agg['buildings_floors'] = buildings_processed.apply(lambda x: x['floors_csv'])\n",
        "building_agg['buildings_descriptions'] = buildings_processed.apply(lambda x: x['descriptions_csv'])\n",
        "building_agg['buildings_details_json'] = buildings_processed.apply(lambda x: x['buildings_details_json'])\n",
        "\n",
        "# Add building type diversity\n",
        "building_type_counts = df_buildings.groupby(building_ref_col)['building_type'].agg(['nunique', 'count'])\n",
        "building_agg['unique_building_types'] = building_type_counts['nunique']\n",
        "building_agg['building_type_diversity'] = building_type_counts['nunique'] / building_type_counts['count']\n",
        "\n",
        "# Most common building type per parcel\n",
        "most_common_type = df_buildings.groupby(building_ref_col)['building_type'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown')\n",
        "building_agg['primary_building_type'] = most_common_type\n",
        "\n",
        "building_agg = building_agg.reset_index()\n",
        "print(f\"Building aggregations shape: {building_agg.shape}\")\n",
        "print(f\"Building aggregations columns: {building_agg.columns.tolist()}\")\n",
        "print(f\"Sample building aggregation (showing structured building details):\")\n",
        "if len(building_agg) > 0:\n",
        "    # Show columns that include structured building info\n",
        "    sample_cols = [building_ref_col, 'num_buildings', 'buildings_areas', 'buildings_types', 'total_built_area']\n",
        "    available_sample_cols = [col for col in sample_cols if col in building_agg.columns]\n",
        "    print(building_agg[available_sample_cols].head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing units data...\n",
            "Unit aggregations shape: (4977, 22)\n",
            "Unit aggregations columns: ['parcel_ref', 'num_units', 'total_floor_area', 'avg_floor_area', 'max_floor_area', 'min_floor_area', 'avg_year_built', 'oldest_year_built', 'newest_year_built', 'total_participation', 'avg_participation', 'units_years_built', 'units_ages', 'units_floor_areas', 'units_use_types', 'units_details_json', 'unique_use_types', 'use_type_diversity', 'primary_use_type', 'residential_ratio', 'province', 'municipality']\n",
            "Sample unit aggregation (showing structured unit details):\n",
            "       parcel_ref  num_units units_years_built units_ages units_use_types  \\\n",
            "0  000100100DD88G          1              1940         85     Residencial   \n",
            "1  000100100DD99E          1              1970         55     Residencial   \n",
            "2  000100100DE90A          1              1980         45      Industrial   \n",
            "\n",
            "   total_floor_area  \n",
            "0             404.0  \n",
            "1             179.0  \n",
            "2               4.0  \n"
          ]
        }
      ],
      "source": [
        "# Aggregate units data by parcel\n",
        "print(\"Processing units data...\")\n",
        "\n",
        "# Create unit aggregations\n",
        "unit_agg = df_units.groupby(unit_ref_col).agg({\n",
        "    'id': 'count',  # Count of units per parcel\n",
        "    'floor_area': ['sum', 'mean', 'max', 'min'],  # Floor area statistics\n",
        "    'year_built': ['mean', 'min', 'max'],  # Building year statistics\n",
        "    'participation': ['sum', 'mean'],  # Participation statistics\n",
        "}).round(2)\n",
        "\n",
        "# Flatten column names\n",
        "unit_agg.columns = [\n",
        "    'num_units', \n",
        "    'total_floor_area', 'avg_floor_area', 'max_floor_area', 'min_floor_area',\n",
        "    'avg_year_built', 'oldest_year_built', 'newest_year_built',\n",
        "    'total_participation', 'avg_participation'\n",
        "]\n",
        "\n",
        "# Add individual unit details - structured approach for unlimited units\n",
        "def process_units_for_parcel(group):\n",
        "    current_year = datetime.now().year\n",
        "    \n",
        "    # Lists for CSV format\n",
        "    years_built = []\n",
        "    ages = []\n",
        "    floor_areas = []\n",
        "    use_types = []\n",
        "    \n",
        "    # Detailed dict for JSON format\n",
        "    unit_details = []\n",
        "    \n",
        "    for idx, unit in group.iterrows():\n",
        "        year_built = unit['year_built'] if pd.notna(unit['year_built']) else None\n",
        "        age = current_year - year_built if year_built is not None else None\n",
        "        floor_area = unit['floor_area'] if pd.notna(unit['floor_area']) else 0\n",
        "        use_type = unit['use_type'] if pd.notna(unit['use_type']) else 'Unknown'\n",
        "        \n",
        "        # Add to lists (for CSV columns)\n",
        "        if year_built is not None:\n",
        "            years_built.append(int(year_built))\n",
        "            ages.append(int(age))\n",
        "        floor_areas.append(floor_area)\n",
        "        use_types.append(use_type)\n",
        "        \n",
        "        # Add to detailed structure (for JSON column)\n",
        "        unit_details.append({\n",
        "            'unit_id': int(unit['id']),\n",
        "            'year_built': int(year_built) if year_built is not None else None,\n",
        "            'age': int(age) if age is not None else None,\n",
        "            'floor_area': floor_area,\n",
        "            'use_type': use_type,\n",
        "            'participation': unit['participation'] if pd.notna(unit['participation']) else 0\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        'years_built_csv': ', '.join(map(str, years_built)),\n",
        "        'ages_csv': ', '.join(map(str, ages)),\n",
        "        'floor_areas_csv': ', '.join(map(str, floor_areas)),\n",
        "        'use_types_csv': ', '.join(use_types),\n",
        "        'units_details_json': json.dumps(unit_details, ensure_ascii=False)\n",
        "    }\n",
        "\n",
        "# Process all units for each parcel\n",
        "units_processed = df_units.groupby(unit_ref_col).apply(process_units_for_parcel)\n",
        "\n",
        "# Add the structured unit data to aggregations\n",
        "unit_agg['units_years_built'] = units_processed.apply(lambda x: x['years_built_csv'])\n",
        "unit_agg['units_ages'] = units_processed.apply(lambda x: x['ages_csv'])\n",
        "unit_agg['units_floor_areas'] = units_processed.apply(lambda x: x['floor_areas_csv'])\n",
        "unit_agg['units_use_types'] = units_processed.apply(lambda x: x['use_types_csv'])\n",
        "unit_agg['units_details_json'] = units_processed.apply(lambda x: x['units_details_json'])\n",
        "\n",
        "# Add use type diversity and statistics\n",
        "use_type_stats = df_units.groupby(unit_ref_col)['use_type'].agg(['nunique', 'count'])\n",
        "unit_agg['unique_use_types'] = use_type_stats['nunique']\n",
        "unit_agg['use_type_diversity'] = use_type_stats['nunique'] / use_type_stats['count']\n",
        "\n",
        "# Most common use type per parcel\n",
        "most_common_use = df_units.groupby(unit_ref_col)['use_type'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown')\n",
        "unit_agg['primary_use_type'] = most_common_use\n",
        "\n",
        "# Calculate residential vs non-residential ratios\n",
        "def calc_residential_ratio(group):\n",
        "    total = len(group)\n",
        "    residential = (group == 'Residencial').sum()\n",
        "    return residential / total if total > 0 else 0\n",
        "\n",
        "residential_ratio = df_units.groupby(unit_ref_col)['use_type'].apply(calc_residential_ratio)\n",
        "unit_agg['residential_ratio'] = residential_ratio\n",
        "\n",
        "# Province and municipality (taking first occurrence per parcel)\n",
        "location_info = df_units.groupby(unit_ref_col)[['province', 'municipality']].first()\n",
        "unit_agg['province'] = location_info['province']\n",
        "unit_agg['municipality'] = location_info['municipality']\n",
        "\n",
        "unit_agg = unit_agg.reset_index()\n",
        "print(f\"Unit aggregations shape: {unit_agg.shape}\")\n",
        "print(f\"Unit aggregations columns: {unit_agg.columns.tolist()}\")\n",
        "print(f\"Sample unit aggregation (showing structured unit details):\")\n",
        "if len(unit_agg) > 0:\n",
        "    # Show columns that include structured unit info\n",
        "    sample_cols = [unit_ref_col, 'num_units', 'units_years_built', 'units_ages', 'units_use_types', 'total_floor_area']\n",
        "    available_sample_cols = [col for col in sample_cols if col in unit_agg.columns]\n",
        "    print(unit_agg[available_sample_cols].head(3))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Merge All Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting with parcels: (10110, 10)\n",
            "Merging buildings data...\n",
            "After merging buildings: (10110, 23)\n",
            "Merging units data...\n",
            "After merging units: (10110, 45)\n",
            "\n",
            "Final DataFrame shape: (10110, 45)\n",
            "Final DataFrame columns: 45\n",
            "\n",
            "Sample of merged data with structured building/unit details:\n",
            "  referencia_catastral  superficie_parcela  num_buildings  num_units  \\\n",
            "0       000100100DD99E              252.55            0.0        1.0   \n",
            "1       000100100DE90A                4.03            0.0        1.0   \n",
            "2       000100100DE90B               88.54            0.0        1.0   \n",
            "\n",
            "  units_years_built buildings_areas  \n",
            "0              1970             NaN  \n",
            "1              1980             NaN  \n",
            "2              1987             NaN  \n",
            "\n",
            "💡 Example of how to use structured data:\n",
            "   Parcel 000100100DD99E has units built in: ['1970']\n",
            "   In your code: years = df['units_years_built'].str.split(', ')\n",
            "   First unit details: {'unit_id': 4, 'year_built': 1970, 'age': 55, 'floor_area': 179.0, 'use_type': 'Residencial', 'participation': 100.0}\n",
            "   In your code: import json; units = json.loads(df['units_details_json'].iloc[0])\n"
          ]
        }
      ],
      "source": [
        "# Start with parcels as the base\n",
        "final_df = df_parcels.copy()\n",
        "print(f\"Starting with parcels: {final_df.shape}\")\n",
        "\n",
        "# Merge buildings aggregations\n",
        "print(\"Merging buildings data...\")\n",
        "final_df = final_df.merge(building_agg, left_on=parcel_ref_col, right_on=building_ref_col, how='left')\n",
        "print(f\"After merging buildings: {final_df.shape}\")\n",
        "    \n",
        "# Merge units aggregations  \n",
        "print(\"Merging units data...\")\n",
        "final_df = final_df.merge(unit_agg, left_on=parcel_ref_col, right_on=unit_ref_col, how='left')\n",
        "print(f\"After merging units: {final_df.shape}\")\n",
        "\n",
        "# Fill NaN values for count and numeric columns with appropriate defaults\n",
        "count_columns = [col for col in final_df.columns if col.startswith('num_')]\n",
        "area_columns = [col for col in final_df.columns if 'area' in col.lower() and col.startswith(('total_', 'avg_', 'max_', 'min_'))]\n",
        "ratio_columns = [col for col in final_df.columns if any(term in col.lower() for term in ['ratio', 'diversity'])]\n",
        "\n",
        "final_df[count_columns] = final_df[count_columns].fillna(0)\n",
        "final_df[area_columns] = final_df[area_columns].fillna(0)  \n",
        "final_df[ratio_columns] = final_df[ratio_columns].fillna(0)\n",
        "\n",
        "# Fill categorical columns with appropriate defaults\n",
        "categorical_fill_values = {\n",
        "    'primary_building_type': 'No Buildings',\n",
        "    'primary_use_type': 'No Units',\n",
        "    'unique_building_types': 0,\n",
        "    'unique_use_types': 0\n",
        "}\n",
        "\n",
        "for col, fill_value in categorical_fill_values.items():\n",
        "    if col in final_df.columns:\n",
        "        final_df[col] = final_df[col].fillna(fill_value)\n",
        "\n",
        "print(f\"\\nFinal DataFrame shape: {final_df.shape}\")\n",
        "print(f\"Final DataFrame columns: {len(final_df.columns)}\")\n",
        "\n",
        "# Show a sample of merged data with structured details\n",
        "print(f\"\\nSample of merged data with structured building/unit details:\")\n",
        "key_display_cols = [parcel_ref_col, 'superficie_parcela', 'num_buildings', 'num_units', 'units_years_built', 'buildings_areas']\n",
        "available_cols = [col for col in key_display_cols if col in final_df.columns]\n",
        "if available_cols:\n",
        "    print(final_df[available_cols].head(3))\n",
        "    \n",
        "# Show example of how to use the structured data\n",
        "print(f\"\\n💡 Example of how to use structured data:\")\n",
        "if 'units_years_built' in final_df.columns and len(final_df) > 0:\n",
        "    sample_row = final_df.iloc[0]\n",
        "    if pd.notna(sample_row['units_years_built']) and sample_row['units_years_built'] != '':\n",
        "        years_list = sample_row['units_years_built'].split(', ')\n",
        "        print(f\"   Parcel {sample_row[parcel_ref_col]} has units built in: {years_list}\")\n",
        "        print(f\"   In your code: years = df['units_years_built'].str.split(', ')\")\n",
        "    \n",
        "    if 'units_details_json' in final_df.columns and pd.notna(sample_row['units_details_json']):\n",
        "        try:\n",
        "            units_json = json.loads(sample_row['units_details_json'])\n",
        "            if units_json:\n",
        "                print(f\"   First unit details: {units_json[0]}\")\n",
        "                print(f\"   In your code: import json; units = json.loads(df['units_details_json'].iloc[0])\")\n",
        "        except:\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Add Computed Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing additional metrics...\n",
            "✓ Added building density per sqm\n",
            "✓ Added unit density per sqm\n",
            "✓ Added average units per building\n",
            "✓ Added building coverage ratio\n",
            "✓ Added floor area ratio (FAR)\n",
            "✓ Added total constructed area\n",
            "✓ Added average building age\n",
            "✓ Added area efficiency ratio\n",
            "✓ Added parcel utilization score\n",
            "\n",
            "Final DataFrame with computed metrics shape: (10110, 54)\n",
            "Computed metrics added: 10\n",
            "Computed columns: ['units_ages', 'residential_ratio', 'building_density_per_sqm', 'unit_density_per_sqm', 'building_coverage_ratio', 'floor_area_ratio', 'total_constructed_area', 'avg_building_age', 'area_efficiency_ratio', 'utilization_score']\n"
          ]
        }
      ],
      "source": [
        "# Add additional computed metrics\n",
        "print(\"Computing additional metrics...\")\n",
        "\n",
        "# Building density (buildings per parcel area)\n",
        "if 'num_buildings' in final_df.columns and 'superficie_parcela' in final_df.columns:\n",
        "    final_df['building_density_per_sqm'] = final_df['num_buildings'] / (final_df['superficie_parcela'] + 1e-6)\n",
        "    print(\"✓ Added building density per sqm\")\n",
        "\n",
        "# Unit density (units per parcel area)  \n",
        "if 'num_units' in final_df.columns and 'superficie_parcela' in final_df.columns:\n",
        "    final_df['unit_density_per_sqm'] = final_df['num_units'] / (final_df['superficie_parcela'] + 1e-6)\n",
        "    print(\"✓ Added unit density per sqm\")\n",
        "\n",
        "# Average units per building\n",
        "if 'num_units' in final_df.columns and 'num_buildings' in final_df.columns:\n",
        "    final_df['avg_units_per_building'] = final_df['num_units'] / (final_df['num_buildings'] + 1e-6)\n",
        "    final_df['avg_units_per_building'] = final_df['avg_units_per_building'].replace([np.inf, -np.inf], 0)\n",
        "    print(\"✓ Added average units per building\")\n",
        "\n",
        "# Development intensity (built area vs parcel area)\n",
        "if 'total_built_area' in final_df.columns and 'superficie_parcela' in final_df.columns:\n",
        "    final_df['building_coverage_ratio'] = final_df['total_built_area'] / (final_df['superficie_parcela'] + 1e-6)\n",
        "    final_df['building_coverage_ratio'] = final_df['building_coverage_ratio'].replace([np.inf, -np.inf], 0)\n",
        "    print(\"✓ Added building coverage ratio\")\n",
        "\n",
        "# Floor area ratio (total floor area vs parcel area)\n",
        "if 'total_floor_area' in final_df.columns and 'superficie_parcela' in final_df.columns:\n",
        "    final_df['floor_area_ratio'] = final_df['total_floor_area'] / (final_df['superficie_parcela'] + 1e-6)\n",
        "    final_df['floor_area_ratio'] = final_df['floor_area_ratio'].replace([np.inf, -np.inf], 0)\n",
        "    print(\"✓ Added floor area ratio (FAR)\")\n",
        "\n",
        "# Combined total constructed area (buildings + units)\n",
        "if 'total_built_area' in final_df.columns and 'total_floor_area' in final_df.columns:\n",
        "    final_df['total_constructed_area'] = final_df['total_built_area'] + final_df['total_floor_area']\n",
        "    print(\"✓ Added total constructed area\")\n",
        "\n",
        "# Development age metrics\n",
        "if 'avg_year_built' in final_df.columns:\n",
        "    current_year = datetime.now().year\n",
        "    final_df['avg_building_age'] = current_year - final_df['avg_year_built']\n",
        "    final_df['avg_building_age'] = final_df['avg_building_age'].fillna(0)\n",
        "    print(\"✓ Added average building age\")\n",
        "\n",
        "# Property value indicators (based on area, age, type)\n",
        "# Efficiency ratio (floor area per building area)\n",
        "if 'total_floor_area' in final_df.columns and 'total_built_area' in final_df.columns:\n",
        "    final_df['area_efficiency_ratio'] = final_df['total_floor_area'] / (final_df['total_built_area'] + 1e-6)\n",
        "    final_df['area_efficiency_ratio'] = final_df['area_efficiency_ratio'].replace([np.inf, -np.inf], 0)\n",
        "    print(\"✓ Added area efficiency ratio\")\n",
        "\n",
        "# Parcel utilization score (0-1 scale)\n",
        "if all(col in final_df.columns for col in ['building_coverage_ratio', 'floor_area_ratio', 'num_buildings', 'superficie_parcela']):\n",
        "    # Normalize factors for scoring\n",
        "    coverage_norm = np.clip(final_df['building_coverage_ratio'], 0, 1)\n",
        "    far_norm = np.clip(final_df['floor_area_ratio'] / 3, 0, 1)  # FAR of 3 = max score\n",
        "    density_norm = np.clip(final_df['building_density_per_sqm'] * 100, 0, 1)  # Normalize density\n",
        "    \n",
        "    final_df['utilization_score'] = (coverage_norm * 0.4 + far_norm * 0.4 + density_norm * 0.2).round(3)\n",
        "    print(\"✓ Added parcel utilization score\")\n",
        "\n",
        "print(f\"\\nFinal DataFrame with computed metrics shape: {final_df.shape}\")\n",
        "\n",
        "# Show summary of new computed columns\n",
        "computed_cols = [col for col in final_df.columns if any(term in col for term in \n",
        "                ['density', 'ratio', 'efficiency', 'score', 'age', 'constructed'])]\n",
        "print(f\"Computed metrics added: {len(computed_cols)}\")\n",
        "print(f\"Computed columns: {computed_cols}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Export to Excel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting to catastro_comprehensive_data_20250701_120602.xlsx...\n",
            "✅ Successfully exported to catastro_comprehensive_data_20250701_120602.xlsx\n",
            "📊 File contains 10,110 rows and 54 columns\n",
            "📁 File size: 17.75 MB\n",
            "\n",
            "📋 Sheets created:\n",
            "  • Comprehensive_Data: Complete dataset with all columns\n",
            "  • Search_Ready_Data: Key columns optimized for search functionality\n",
            "  • Detailed_Properties: Structured building and unit details (CSV + JSON)\n",
            "  • Building_Summary: Statistics grouped by building type\n",
            "  • Usage_Summary: Statistics grouped by usage type\n",
            "  • Municipality_Summary: Statistics grouped by municipality\n",
            "  • Statistical_Summary: Descriptive statistics for numeric columns\n",
            "  • Column_Info: Metadata about each column\n",
            "\n",
            "🎯 Perfect for your search system! Use 'Search_Ready_Data' sheet for:\n",
            "  • Filtering by region (municipio, provincia)\n",
            "  • Area-based searches (superficie_parcela, total areas)\n",
            "  • Usage type filtering (primary_use_type, residential_ratio)\n",
            "  • Development intensity (utilization_score, coverage ratios)\n",
            "  • Building characteristics (age, density, types)\n",
            "  • Individual building/unit data (units_years_built, units_ages)\n",
            "\n",
            "🏠 Structured Data Features (UNLIMITED buildings/units per parcel!):\n",
            "  • CSV format: units_years_built = '1970, 1980, 1990'\n",
            "  • CSV format: units_ages = '54, 44, 34'\n",
            "  • CSV format: buildings_areas = '120, 80, 200'\n",
            "  • JSON format: units_details_json = complete unit info with IDs\n",
            "  • JSON format: buildings_details_json = complete building info with IDs\n",
            "  • No limits on number of buildings or units per parcel!\n",
            "  • Easy to parse in your search system - split by comma or parse JSON\n"
          ]
        }
      ],
      "source": [
        "# Export to Excel with multiple sheets\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "excel_filename = f'catastro_comprehensive_data_{timestamp}.xlsx'\n",
        "\n",
        "print(f\"Exporting to {excel_filename}...\")\n",
        "\n",
        "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
        "    # Main comprehensive sheet\n",
        "    final_df.to_excel(writer, sheet_name='Comprehensive_Data', index=False)\n",
        "    \n",
        "    # Key metrics sheet for search/analysis (most important columns)\n",
        "    key_cols = [\n",
        "        parcel_ref_col, 'superficie_parcela', 'municipio', 'provincia',\n",
        "        'num_buildings', 'num_units', \n",
        "        'total_built_area', 'total_floor_area', 'total_constructed_area',\n",
        "        'primary_building_type', 'primary_use_type', 'residential_ratio',\n",
        "        'avg_year_built', 'avg_building_age',\n",
        "        'building_density_per_sqm', 'unit_density_per_sqm', 'floor_area_ratio',\n",
        "        'building_coverage_ratio', 'utilization_score',\n",
        "        # Add structured details to search sheet for easy filtering\n",
        "        'units_years_built', 'units_ages', 'units_use_types',\n",
        "        'buildings_areas', 'buildings_types'\n",
        "    ]\n",
        "    available_key_cols = [col for col in key_cols if col in final_df.columns]\n",
        "    final_df[available_key_cols].to_excel(writer, sheet_name='Search_Ready_Data', index=False)\n",
        "    \n",
        "    # Detailed Building & Unit Info sheet (with structured data)\n",
        "    detail_cols = [\n",
        "        parcel_ref_col, 'superficie_parcela', 'num_buildings', 'num_units',\n",
        "        # Building structured data\n",
        "        'buildings_areas', 'buildings_types', 'buildings_floors', 'buildings_descriptions',\n",
        "        'buildings_details_json',\n",
        "        # Unit structured data  \n",
        "        'units_years_built', 'units_ages', 'units_floor_areas', 'units_use_types',\n",
        "        'units_details_json',\n",
        "        # Summary stats\n",
        "        'total_built_area', 'total_floor_area', 'avg_year_built'\n",
        "    ]\n",
        "    available_detail_cols = [col for col in detail_cols if col in final_df.columns]\n",
        "    final_df[available_detail_cols].to_excel(writer, sheet_name='Detailed_Properties', index=False)\n",
        "    \n",
        "    # Building statistics summary\n",
        "    building_summary = final_df.groupby('primary_building_type').agg({\n",
        "        'num_buildings': ['count', 'sum', 'mean'],\n",
        "        'total_built_area': ['sum', 'mean'],\n",
        "        'avg_built_area': 'mean',\n",
        "        'superficie_parcela': 'mean'\n",
        "    }).round(2)\n",
        "    building_summary.columns = ['Parcels_Count', 'Total_Buildings', 'Avg_Buildings_per_Parcel', \n",
        "                               'Total_Built_Area', 'Avg_Built_Area_per_Parcel', 'Avg_Built_Area_per_Building', 'Avg_Parcel_Size']\n",
        "    building_summary.to_excel(writer, sheet_name='Building_Summary')\n",
        "    \n",
        "    # Usage type analysis\n",
        "    usage_summary = final_df.groupby('primary_use_type').agg({\n",
        "        'num_units': ['count', 'sum', 'mean'],\n",
        "        'total_floor_area': ['sum', 'mean'],\n",
        "        'residential_ratio': 'mean',\n",
        "        'avg_year_built': 'mean'\n",
        "    }).round(2)\n",
        "    usage_summary.columns = ['Parcels_Count', 'Total_Units', 'Avg_Units_per_Parcel',\n",
        "                            'Total_Floor_Area', 'Avg_Floor_Area_per_Parcel', 'Avg_Residential_Ratio', 'Avg_Year_Built']\n",
        "    usage_summary.to_excel(writer, sheet_name='Usage_Summary')\n",
        "    \n",
        "    # Municipality analysis\n",
        "    municipality_summary = final_df.groupby('municipio').agg({\n",
        "        parcel_ref_col: 'count',\n",
        "        'num_buildings': 'sum',\n",
        "        'num_units': 'sum', \n",
        "        'superficie_parcela': ['sum', 'mean'],\n",
        "        'total_constructed_area': 'sum',\n",
        "        'utilization_score': 'mean'\n",
        "    }).round(2)\n",
        "    municipality_summary.columns = ['Total_Parcels', 'Total_Buildings', 'Total_Units', \n",
        "                                   'Total_Land_Area', 'Avg_Parcel_Size', 'Total_Constructed_Area', 'Avg_Utilization_Score']\n",
        "    municipality_summary.to_excel(writer, sheet_name='Municipality_Summary')\n",
        "    \n",
        "    # Summary statistics sheet\n",
        "    numeric_cols = final_df.select_dtypes(include=[np.number]).columns\n",
        "    summary_stats = final_df[numeric_cols].describe()\n",
        "    summary_stats.to_excel(writer, sheet_name='Statistical_Summary')\n",
        "    \n",
        "    # Column information sheet (handle complex data types safely)\n",
        "    def safe_nunique(series):\n",
        "        try:\n",
        "            return series.nunique()\n",
        "        except (TypeError, ValueError):\n",
        "            # For unhashable types like dicts, count non-null values instead\n",
        "            return series.notna().sum()\n",
        "    \n",
        "    def safe_sample_value(series):\n",
        "        try:\n",
        "            if len(series) > 0 and series.notna().any():\n",
        "                sample_val = series.dropna().iloc[0]\n",
        "                # Truncate very long values\n",
        "                str_val = str(sample_val)\n",
        "                return str_val[:100] + \"...\" if len(str_val) > 100 else str_val\n",
        "            return ''\n",
        "        except:\n",
        "            return 'Complex data type'\n",
        "    \n",
        "    col_info = pd.DataFrame({\n",
        "        'Column_Name': final_df.columns,\n",
        "        'Data_Type': [str(final_df[col].dtype) for col in final_df.columns],\n",
        "        'Non_Null_Count': [final_df[col].notna().sum() for col in final_df.columns],\n",
        "        'Null_Percentage': [round(final_df[col].isna().sum() / len(final_df) * 100, 2) for col in final_df.columns],\n",
        "        'Unique_Values': [safe_nunique(final_df[col]) for col in final_df.columns],\n",
        "        'Sample_Value': [safe_sample_value(final_df[col]) for col in final_df.columns]\n",
        "    })\n",
        "    col_info.to_excel(writer, sheet_name='Column_Info', index=False)\n",
        "\n",
        "print(f\"✅ Successfully exported to {excel_filename}\")\n",
        "print(f\"📊 File contains {len(final_df):,} rows and {len(final_df.columns)} columns\")\n",
        "print(f\"📁 File size: {round(sum(final_df.memory_usage(deep=True)) / 1024**2, 2)} MB\")\n",
        "\n",
        "print(\"\\n📋 Sheets created:\")\n",
        "print(\"  • Comprehensive_Data: Complete dataset with all columns\")\n",
        "print(\"  • Search_Ready_Data: Key columns optimized for search functionality\")\n",
        "print(\"  • Detailed_Properties: Structured building and unit details (CSV + JSON)\")\n",
        "print(\"  • Building_Summary: Statistics grouped by building type\")\n",
        "print(\"  • Usage_Summary: Statistics grouped by usage type\")\n",
        "print(\"  • Municipality_Summary: Statistics grouped by municipality\")\n",
        "print(\"  • Statistical_Summary: Descriptive statistics for numeric columns\")\n",
        "print(\"  • Column_Info: Metadata about each column\")\n",
        "\n",
        "print(f\"\\n🎯 Perfect for your search system! Use 'Search_Ready_Data' sheet for:\")\n",
        "print(\"  • Filtering by region (municipio, provincia)\")\n",
        "print(\"  • Area-based searches (superficie_parcela, total areas)\")\n",
        "print(\"  • Usage type filtering (primary_use_type, residential_ratio)\")  \n",
        "print(\"  • Development intensity (utilization_score, coverage ratios)\")\n",
        "print(\"  • Building characteristics (age, density, types)\")\n",
        "print(\"  • Individual building/unit data (units_years_built, units_ages)\")\n",
        "\n",
        "print(f\"\\n🏠 Structured Data Features (UNLIMITED buildings/units per parcel!):\")\n",
        "print(\"  • CSV format: units_years_built = '1970, 1980, 1990'\")\n",
        "print(\"  • CSV format: units_ages = '54, 44, 34'\")\n",
        "print(\"  • CSV format: buildings_areas = '120, 80, 200'\")\n",
        "print(\"  • JSON format: units_details_json = complete unit info with IDs\")\n",
        "print(\"  • JSON format: buildings_details_json = complete building info with IDs\")\n",
        "print(\"  • No limits on number of buildings or units per parcel!\")\n",
        "print(\"  • Easy to parse in your search system - split by comma or parse JSON\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Data Summary and Quality Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "🏗️  CATASTRO DATA PROCESSING COMPLETE\n",
            "============================================================\n",
            "\n",
            "📊 DATASET OVERVIEW:\n",
            "   • Total parcels processed: 10,110\n",
            "   • Total columns created: 54\n",
            "   • Data coverage: 75.5%\n",
            "\n",
            "🏠 BUILDING & UNIT STATISTICS:\n",
            "   • Total buildings: 6,495\n",
            "   • Parcels with buildings: 1,982 (19.6%)\n",
            "   • Average buildings per parcel: 0.64\n",
            "   • Total units: 7,924\n",
            "   • Parcels with units: 4,977 (49.2%)\n",
            "   • Average units per parcel: 0.78\n",
            "\n",
            "🏘️ GEOGRAPHIC DISTRIBUTION:\n",
            "   • Municipalities covered: 2\n",
            "   • Top municipalities:\n",
            "     1. SELVA: 5,131 parcels\n",
            "     2. SANTA MARIA DEL CAMI: 4,979 parcels\n",
            "   • Provinces covered: 1\n",
            "\n",
            "🏗️ BUILDING CHARACTERISTICS:\n",
            "   • Building types identified: 15\n",
            "     • No Buildings: 8,128 parcels\n",
            "     • VIVIENDA: 1,002 parcels\n",
            "     • ALMACEN: 518 parcels\n",
            "   • Usage types identified: 15\n",
            "     • No Units: 5,133 parcels\n",
            "     • Agrario: 2,601 parcels\n",
            "     • Residencial: 1,880 parcels\n",
            "\n",
            "📏 AREA STATISTICS:\n",
            "   • Total land area: 85,292,442 sqm\n",
            "   • Average parcel size: 8436 sqm\n",
            "   • Largest parcel: 4,102,279 sqm\n",
            "   • Total constructed area: 1,469,749 sqm\n",
            "\n",
            "🔍 SEARCH-READY FEATURES:\n",
            "   ✓ Geographic filtering (municipio, provincia)\n",
            "   ✓ Area-based searches (parcel size, built area, floor area)\n",
            "   ✓ Usage type filtering (residential, industrial, etc.)\n",
            "   ✓ Development intensity metrics (coverage ratios, density)\n",
            "   ✓ Building characteristics (age, type, count)\n",
            "   ✓ Utilization scoring (0-1 scale for development potential)\n",
            "\n",
            "📁 EXCEL FILE READY:\n",
            "   📂 File: catastro_comprehensive_data_20250701_120602.xlsx\n",
            "   📋 Best sheet for search: 'Search_Ready_Data'\n",
            "   🎯 Contains 7 key search columns\n",
            "\n",
            "🚀 NEXT STEPS FOR SEARCH SYSTEM:\n",
            "   1. Import 'Search_Ready_Data' sheet into your search database\n",
            "   2. Index key columns: municipio, primary_use_type, superficie_parcela\n",
            "   3. Create range filters for: area, utilization_score, building counts\n",
            "   4. Use Municipality_Summary for region-level insights\n",
            "============================================================\n",
            "✅ Ready to build your catastro search system!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Display comprehensive data summary\n",
        "print(\"=\" * 60)\n",
        "print(\"🏗️  CATASTRO DATA PROCESSING COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n📊 DATASET OVERVIEW:\")\n",
        "print(f\"   • Total parcels processed: {len(final_df):,}\")\n",
        "print(f\"   • Total columns created: {len(final_df.columns)}\")\n",
        "print(f\"   • Data coverage: {round((final_df.notna().sum().sum() / (len(final_df) * len(final_df.columns))) * 100, 1)}%\")\n",
        "\n",
        "print(f\"\\n🏠 BUILDING & UNIT STATISTICS:\")\n",
        "if 'num_buildings' in final_df.columns:\n",
        "    print(f\"   • Total buildings: {final_df['num_buildings'].sum():,.0f}\")\n",
        "    print(f\"   • Parcels with buildings: {(final_df['num_buildings'] > 0).sum():,} ({((final_df['num_buildings'] > 0).sum() / len(final_df) * 100):.1f}%)\")\n",
        "    print(f\"   • Average buildings per parcel: {final_df['num_buildings'].mean():.2f}\")\n",
        "\n",
        "if 'num_units' in final_df.columns:\n",
        "    print(f\"   • Total units: {final_df['num_units'].sum():,.0f}\")\n",
        "    print(f\"   • Parcels with units: {(final_df['num_units'] > 0).sum():,} ({((final_df['num_units'] > 0).sum() / len(final_df) * 100):.1f}%)\")\n",
        "    print(f\"   • Average units per parcel: {final_df['num_units'].mean():.2f}\")\n",
        "\n",
        "print(f\"\\n🏘️ GEOGRAPHIC DISTRIBUTION:\")\n",
        "if 'municipio' in final_df.columns:\n",
        "    municipality_counts = final_df['municipio'].value_counts()\n",
        "    print(f\"   • Municipalities covered: {municipality_counts.nunique()}\")\n",
        "    print(f\"   • Top municipalities:\")\n",
        "    for i, (muni, count) in enumerate(municipality_counts.head(3).items()):\n",
        "        print(f\"     {i+1}. {muni}: {count:,} parcels\")\n",
        "\n",
        "if 'provincia' in final_df.columns:\n",
        "    province_counts = final_df['provincia'].value_counts()\n",
        "    print(f\"   • Provinces covered: {province_counts.nunique()}\")\n",
        "\n",
        "print(f\"\\n🏗️ BUILDING CHARACTERISTICS:\")\n",
        "if 'primary_building_type' in final_df.columns:\n",
        "    building_types = final_df['primary_building_type'].value_counts()\n",
        "    print(f\"   • Building types identified: {building_types.nunique()}\")\n",
        "    for bt, count in building_types.head(3).items():\n",
        "        print(f\"     • {bt}: {count:,} parcels\")\n",
        "\n",
        "if 'primary_use_type' in final_df.columns:\n",
        "    use_types = final_df['primary_use_type'].value_counts()\n",
        "    print(f\"   • Usage types identified: {use_types.nunique()}\")\n",
        "    for ut, count in use_types.head(3).items():\n",
        "        print(f\"     • {ut}: {count:,} parcels\")\n",
        "\n",
        "print(f\"\\n📏 AREA STATISTICS:\")\n",
        "if 'superficie_parcela' in final_df.columns:\n",
        "    print(f\"   • Total land area: {final_df['superficie_parcela'].sum():,.0f} sqm\")\n",
        "    print(f\"   • Average parcel size: {final_df['superficie_parcela'].mean():.0f} sqm\")\n",
        "    print(f\"   • Largest parcel: {final_df['superficie_parcela'].max():,.0f} sqm\")\n",
        "\n",
        "if 'total_constructed_area' in final_df.columns:\n",
        "    total_constructed = final_df['total_constructed_area'].sum()\n",
        "    print(f\"   • Total constructed area: {total_constructed:,.0f} sqm\")\n",
        "\n",
        "print(f\"\\n🔍 SEARCH-READY FEATURES:\")\n",
        "search_features = [\n",
        "    '✓ Geographic filtering (municipio, provincia)',\n",
        "    '✓ Area-based searches (parcel size, built area, floor area)',\n",
        "    '✓ Usage type filtering (residential, industrial, etc.)',\n",
        "    '✓ Development intensity metrics (coverage ratios, density)',\n",
        "    '✓ Building characteristics (age, type, count)',\n",
        "    '✓ Utilization scoring (0-1 scale for development potential)'\n",
        "]\n",
        "for feature in search_features:\n",
        "    print(f\"   {feature}\")\n",
        "\n",
        "print(f\"\\n📁 EXCEL FILE READY:\")\n",
        "print(f\"   📂 File: {excel_filename}\")\n",
        "print(f\"   📋 Best sheet for search: 'Search_Ready_Data'\")\n",
        "print(f\"   🎯 Contains {len([col for col in final_df.columns if col in ['referencia_catastral', 'superficie_parcela', 'municipio', 'num_buildings', 'num_units', 'primary_use_type', 'utilization_score']])} key search columns\")\n",
        "\n",
        "print(f\"\\n🚀 NEXT STEPS FOR SEARCH SYSTEM:\")\n",
        "print(f\"   1. Import 'Search_Ready_Data' sheet into your search database\")\n",
        "print(f\"   2. Index key columns: municipio, primary_use_type, superficie_parcela\")\n",
        "print(f\"   3. Create range filters for: area, utilization_score, building counts\")\n",
        "print(f\"   4. Use Municipality_Summary for region-level insights\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"✅ Ready to build your catastro search system!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
